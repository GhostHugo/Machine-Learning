{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week1-nltk-practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c1897502/Machine-Learning/blob/master/week1_nltk_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPNHvEVUH_TN",
        "colab_type": "text"
      },
      "source": [
        "week1-practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8pakw99IELS",
        "colab_type": "code",
        "outputId": "345a1492-6b83-4b17-e9ad-cf466eda6dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "#nltk.download('all')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWklOeXeI8bM",
        "colab_type": "code",
        "outputId": "55b4c4bf-11c8-4bd2-9370-623db47d23dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "sentence1=\"Machine learning is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. \"\n",
        "sentence2=\"It is seen as a subset of artificial intelligence. \"\n",
        "sentence3=\"Machine learning algorithms build a mathematical model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to perform the task. \"\n",
        "paragraph=sentence1+sentence2+sentence3\n",
        "print (paragraph)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Machine learning is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample learning data, known as training data, in order to make predictions or decisions without being explicitly programmed to perform the task. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24hFZuBRPIx8",
        "colab_type": "code",
        "outputId": "1f5e482b-15f0-4560-94ab-58fcaae01868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "list_tokens=nltk.tokenize.word_tokenize(paragraph)\n",
        "print (list_tokens)\n",
        "\n",
        "sentence_split=nltk.tokenize.sent_tokenize(paragraph)\n",
        "print (sentence_split)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Machine', 'learning', 'is', 'the', 'scientific', 'study', 'of', 'algorithms', 'and', 'statistical', 'models', 'that', 'computer', 'systems', 'use', 'to', 'perform', 'a', 'specific', 'task', 'without', 'using', 'explicit', 'instructions', ',', 'relying', 'on', 'patterns', 'and', 'inference', 'instead', '.', 'It', 'is', 'seen', 'as', 'a', 'subset', 'of', 'artificial', 'intelligence', '.', 'Machine', 'learning', 'algorithms', 'build', 'a', 'mathematical', 'model', 'based', 'on', 'sample', 'learning', 'data', ',', 'known', 'as', 'training', 'data', ',', 'in', 'order', 'to', 'make', 'predictions', 'or', 'decisions', 'without', 'being', 'explicitly', 'programmed', 'to', 'perform', 'the', 'task', '.']\n",
            "['Machine learning is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead.', 'It is seen as a subset of artificial intelligence.', 'Machine learning algorithms build a mathematical model based on sample learning data, known as training data, in order to make predictions or decisions without being explicitly programmed to perform the task.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91bYpfwnQECx",
        "colab_type": "code",
        "outputId": "8a2d60e2-5830-4fce-d7a2-8b3a47fe67bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "list_sentence_tokens=[]\n",
        "for sentence in sentence_split:\n",
        "  list_sentence_tokens.append(nltk.tokenize.word_tokenize(sentence))\n",
        "for sentence_tokens in list_sentence_tokens:\n",
        "  print (sentence_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Machine', 'learning', 'is', 'the', 'scientific', 'study', 'of', 'algorithms', 'and', 'statistical', 'models', 'that', 'computer', 'systems', 'use', 'to', 'perform', 'a', 'specific', 'task', 'without', 'using', 'explicit', 'instructions', ',', 'relying', 'on', 'patterns', 'and', 'inference', 'instead', '.']\n",
            "['It', 'is', 'seen', 'as', 'a', 'subset', 'of', 'artificial', 'intelligence', '.']\n",
            "['Machine', 'learning', 'algorithms', 'build', 'a', 'mathematical', 'model', 'based', 'on', 'sample', 'learning', 'data', ',', 'known', 'as', 'training', 'data', ',', 'in', 'order', 'to', 'make', 'predictions', 'or', 'decisions', 'without', 'being', 'explicitly', 'programmed', 'to', 'perform', 'the', 'task', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DssPXuFdQuy6",
        "colab_type": "code",
        "outputId": "6ae9aa44-214e-4ad1-a9cc-2cfb8d27bb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "count_word=0\n",
        "for sentence_tokens in list_sentence_tokens:\n",
        "  if \"learning\" in sentence_tokens:\n",
        "    count_word+=1\n",
        "print (\"Number of sentences containing 'learning': \"+str(count_word))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences containing 'learning': 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pvVnf3WRGja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PByvRLYgSg0l",
        "colab_type": "code",
        "outputId": "24ef0c24-ab0e-42a0-a192-16ed8976509f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "list_sentence_lemmas_lower=[]\n",
        "for sentence_tokens in list_sentence_tokens:\n",
        "  list_lemmas=[]\n",
        "  for token in sentence_tokens:\n",
        "    list_lemmas.append(lemmatizer.lemmatize(token).lower())\n",
        "  list_sentence_lemmas_lower.append(list_lemmas)\n",
        "print (list_sentence_lemmas_lower)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['machine', 'learning', 'is', 'the', 'scientific', 'study', 'of', 'algorithm', 'and', 'statistical', 'model', 'that', 'computer', 'system', 'use', 'to', 'perform', 'a', 'specific', 'task', 'without', 'using', 'explicit', 'instruction', ',', 'relying', 'on', 'pattern', 'and', 'inference', 'instead', '.'], ['it', 'is', 'seen', 'a', 'a', 'subset', 'of', 'artificial', 'intelligence', '.'], ['machine', 'learning', 'algorithm', 'build', 'a', 'mathematical', 'model', 'based', 'on', 'sample', 'learning', 'data', ',', 'known', 'a', 'training', 'data', ',', 'in', 'order', 'to', 'make', 'prediction', 'or', 'decision', 'without', 'being', 'explicitly', 'programmed', 'to', 'perform', 'the', 'task', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-XE1Pg1VGLc",
        "colab_type": "code",
        "outputId": "54f14fa8-8f99-42e0-f01a-e30b5877df2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "def get_list_tokens(string):\n",
        "  sentence_split=nltk.tokenize.sent_tokenize(string)\n",
        "  list_tokens=[]\n",
        "  for sentence in sentence_split:\n",
        "    list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
        "    for token in list_tokens_sentence:\n",
        "      list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
        "  return list_tokens\n",
        "\n",
        "print (get_list_tokens(paragraph))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['machine', 'learning', 'is', 'the', 'scientific', 'study', 'of', 'algorithm', 'and', 'statistical', 'model', 'that', 'computer', 'system', 'use', 'to', 'perform', 'a', 'specific', 'task', 'without', 'using', 'explicit', 'instruction', ',', 'relying', 'on', 'pattern', 'and', 'inference', 'instead', '.', 'it', 'is', 'seen', 'a', 'a', 'subset', 'of', 'artificial', 'intelligence', '.', 'machine', 'learning', 'algorithm', 'build', 'a', 'mathematical', 'model', 'based', 'on', 'sample', 'learning', 'data', ',', 'known', 'a', 'training', 'data', ',', 'in', 'order', 'to', 'make', 'prediction', 'or', 'decision', 'without', 'being', 'explicitly', 'programmed', 'to', 'perform', 'the', 'task', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CwHJAJqWxkh",
        "colab_type": "code",
        "outputId": "e1af7b51-d507-4b0a-dd62-356edb065085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "def get_list_tokens_sentences(string):\n",
        "  \n",
        "  sentence_split=nltk.tokenize.sent_tokenize(string)\n",
        "  list_sentence=[]\n",
        "  for sentence in sentence_split:\n",
        "    list_sentence_lemmas=[]\n",
        "    list_sentence_tokens=nltk.tokenize.word_tokenize(sentence)\n",
        "   \n",
        "    for sentence_tokens in list_sentence_tokens:\n",
        "      list_sentence_lemmas.append(lemmatizer.lemmatize(sentence_tokens).lower())\n",
        "      \n",
        "    list_sentence.append(list_sentence_lemmas)\n",
        "  return list_sentence\n",
        "\n",
        "print (get_list_tokens_sentences(paragraph))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['machine', 'learning', 'is', 'the', 'scientific', 'study', 'of', 'algorithm', 'and', 'statistical', 'model', 'that', 'computer', 'system', 'use', 'to', 'perform', 'a', 'specific', 'task', 'without', 'using', 'explicit', 'instruction', ',', 'relying', 'on', 'pattern', 'and', 'inference', 'instead', '.'], ['it', 'is', 'seen', 'a', 'a', 'subset', 'of', 'artificial', 'intelligence', '.'], ['machine', 'learning', 'algorithm', 'build', 'a', 'mathematical', 'model', 'based', 'on', 'sample', 'learning', 'data', ',', 'known', 'a', 'training', 'data', ',', 'in', 'order', 'to', 'make', 'prediction', 'or', 'decision', 'without', 'being', 'explicitly', 'programmed', 'to', 'perform', 'the', 'task', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fX6lUDWdj64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}